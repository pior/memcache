# Optimization #4: Pool Flag slices

## Implementation
- Use stack-allocated [4]Flag array for flag parsing
- Initialize flags slice from stack array to avoid heap allocation in common case
- Most responses have 0-4 flags, so this covers the majority of cases

## Benchmark Results

### Before (baseline from main):
```
BenchmarkClient_Get-8                          329427    3100 ns/op    4834 B/op    18 allocs/op
BenchmarkClient_Get_Miss-8                     513571    2135 ns/op    4816 B/op    18 allocs/op
BenchmarkClient_Set-8                          587281    1913 ns/op    4825 B/op    18 allocs/op
BenchmarkClient_Set_WithTTL-8                  593126    2105 ns/op    4872 B/op    22 allocs/op
BenchmarkClient_Set_LargeValue-8               116791   12589 ns/op   32356 B/op    19 allocs/op
BenchmarkClient_Add-8                          535497    2293 ns/op    4878 B/op    22 allocs/op
BenchmarkClient_Delete-8                       581692    2110 ns/op    4772 B/op    15 allocs/op
BenchmarkClient_Increment-8                    471951    2437 ns/op    4998 B/op    27 allocs/op
BenchmarkClient_Increment_WithTTL-8            446224    2700 ns/op    5219 B/op    31 allocs/op
BenchmarkClient_Increment_NegativeDelta-8      456008    2519 ns/op    5057 B/op    30 allocs/op
BenchmarkClient_MixedOperations-8              513954    2265 ns/op    4838 B/op    20 allocs/op
```

### After (with stack-allocated flag array):
```
BenchmarkClient_Get-8                          548762    2097 ns/op    4814 B/op    18 allocs/op
BenchmarkClient_Get_Miss-8                     554714    2099 ns/op    4814 B/op    18 allocs/op
BenchmarkClient_Set-8                          550824    2102 ns/op    4828 B/op    18 allocs/op
BenchmarkClient_Set_WithTTL-8                  514044    2235 ns/op    4881 B/op    22 allocs/op
BenchmarkClient_Set_LargeValue-8               179509   13989 ns/op   40665 B/op    19 allocs/op
BenchmarkClient_Add-8                          528330    2255 ns/op    4879 B/op    22 allocs/op
BenchmarkClient_Delete-8                       563949    2130 ns/op    4773 B/op    15 allocs/op
BenchmarkClient_Increment-8                    472946    2503 ns/op    4998 B/op    27 allocs/op
BenchmarkClient_Increment_WithTTL-8            444745    2611 ns/op    5219 B/op    31 allocs/op
BenchmarkClient_Increment_NegativeDelta-8      455584    2532 ns/op    5057 B/op    30 allocs/op
BenchmarkClient_MixedOperations-8              529418    2297 ns/op    4837 B/op    20 allocs/op
```

## Analysis
- **Allocations**: No change (still 18-31 allocs/op)
- **Memory**: +8.3KB regression for LargeValue (40665 vs 32356 B/op, +25.7%)
- **Time**: Mixed results:
  - Get: -32.3% improvement (2097ns vs 3100ns)
  - LargeValue: +11.1% regression (13989ns vs 12589ns)
  - Most operations: similar or slight improvements

## Conclusion
The stack-allocated array approach doesn't reduce allocations because the escape analysis
detects that the flags slice escapes when assigned to resp.Flags. The array ends up on
the heap anyway, causing extra overhead especially for large value operations.

**Recommendation**: REJECT this optimization. The memory regression on LargeValue operations
(+8.3KB, +25.7%) outweighs the small latency improvements on other operations. The approach
doesn't achieve the intended goal of avoiding heap allocations.

Better alternative: Would need a different pooling strategy or accept the flag slice allocation
as unavoidable given that Response structs need to retain the flags after the function returns.
